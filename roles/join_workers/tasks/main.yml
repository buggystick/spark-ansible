---
# Prepare DGX workers (Ubuntu) with kubelet/kubeadm/kubectl + containerd, then
# generate a bootstrap token on the control-plane via kubeconfig and join via kubeadm.

- name: Install base packages
  apt:
    name:
      - apt-transport-https
      - ca-certificates
      - curl
      - gnupg
      - lsb-release
      - python3-kubernetes
    state: present
    update_cache: yes

- name: Ensure /etc/apt/keyrings exists
  ansible.builtin.file:
    path: /etc/apt/keyrings
    state: directory
    mode: '0755'

- name: Add Kubernetes apt signing key
  ansible.builtin.apt_key:
    url: "https://pkgs.k8s.io/core:/stable:/{{ k8s_channel | default('v1.30') }}/deb/Release.key"
    state: present
    keyring: /etc/apt/keyrings/kubernetes-apt-keyring.gpg

- name: Add Kubernetes apt repository
  ansible.builtin.apt_repository:
    repo: "deb [signed-by=/etc/apt/keyrings/kubernetes-apt-keyring.gpg] https://pkgs.k8s.io/core:/stable:/{{ k8s_channel | default('v1.30') }}/deb/ /"
    filename: kubernetes
    state: present
    update_cache: yes

- name: Install kubelet, kubeadm, kubectl
  apt:
    name:
      - kubelet
      - kubeadm
      - kubectl
    state: present
    update_cache: yes

- name: Install containerd and cri-tools
  apt:
    name:
      - containerd
      - cri-tools
    state: present

- name: Ensure /etc/containerd exists
  file:
    path: /etc/containerd
    state: directory
    mode: '0755'

- name: Push known-good containerd config (CRI enabled + SystemdCgroup)
  copy:
    dest: /etc/containerd/config.toml
    mode: '0644'
    content: |
      version = 2
      imports = ["/etc/containerd/conf.d/*.toml"]

      root = "/var/lib/containerd"
      state = "/run/containerd"

      [grpc]

      [plugins]
        [plugins."io.containerd.grpc.v1.cri"]
          sandbox_image = "registry.k8s.io/pause:3.9"
          [plugins."io.containerd.grpc.v1.cri".containerd]
            snapshotter = "overlayfs"
            [plugins."io.containerd.grpc.v1.cri".containerd.runtimes]
              [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc]
                runtime_type = "io.containerd.runc.v2"
                [plugins."io.containerd.grpc.v1.cri".containerd.runtimes.runc.options]
                  SystemdCgroup = true

      [debug]
        level = "info"

- name: Ensure crictl talks to containerd
  copy:
    dest: /etc/crictl.yaml
    mode: '0644'
    content: |
      runtime-endpoint: {{ k8s_cri_socket | default('unix:///run/containerd/containerd.sock') }}
      image-endpoint:   {{ k8s_cri_socket | default('unix:///run/containerd/containerd.sock') }}
      timeout: 10
      debug: false

- name: Kernel modules for Kubernetes
  copy:
    dest: /etc/modules-load.d/k8s.conf
    content: |
      br_netfilter
      overlay

- name: Sysctl for Kubernetes
  copy:
    dest: /etc/sysctl.d/99-k8s.conf
    content: |
      net.bridge.bridge-nf-call-iptables = 1
      net.bridge.bridge-nf-call-ip6tables = 1
      net.ipv4.ip_forward = 1

- name: Ensure overlay module is loaded
  community.general.modprobe:
    name: overlay
    state: present

- name: Ensure br_netfilter module is loaded
  community.general.modprobe:
    name: br_netfilter
    state: present

- name: Ensure netfilter sysctl for IPv4 is set
  ansible.posix.sysctl:
    name: net.bridge.bridge-nf-call-iptables
    value: '1'
    state: present
    sysctl_set: true
    reload: true

- name: Ensure netfilter sysctl for IPv6 is set
  ansible.posix.sysctl:
    name: net.bridge.bridge-nf-call-ip6tables
    value: '1'
    state: present
    sysctl_set: true
    reload: true

- name: Ensure IPv4 forwarding is enabled
  ansible.posix.sysctl:
    name: net.ipv4.ip_forward
    value: '1'
    state: present
    sysctl_set: true
    reload: true

- name: Restart & enable containerd
  systemd:
    name: containerd
    state: restarted
    enabled: yes

- name: Enable kubelet
  systemd:
    name: kubelet
    enabled: yes

- name: Generate shared bootstrap token (reused by all workers)
  run_once: true
  delegate_to: localhost
  delegate_facts: true
  set_fact:
    kubeadm_token_id: "{{ lookup('password', '/dev/null length=6 chars=hex') }}"
    kubeadm_token_secret: "{{ lookup('password', '/dev/null length=16 chars=hex') }}"
    kubeadm_token_expiration: "{{ lookup('pipe', 'date -u -d \"+' ~ (kubeadm_token_ttl_hours | default(24)) ~ ' hours\" +\"%Y-%m-%dT%H:%M:%SZ\"') }}"

- name: Render bootstrap token secret manifest
  copy:
    dest: /tmp/bootstrap-token.yaml
    content: |
      apiVersion: v1
      kind: Secret
      metadata:
        name: bootstrap-token-{{ hostvars['localhost'].kubeadm_token_id }}
        namespace: kube-system
      type: bootstrap.kubernetes.io/token
      stringData:
        description: "bootstrap token for DGX worker join"
        token-id: "{{ hostvars['localhost'].kubeadm_token_id }}"
        token-secret: "{{ hostvars['localhost'].kubeadm_token_secret }}"
        auth-extra-groups: system:bootstrappers,system:bootstrappers:kubeadm:default-node-token
        expiration: "{{ hostvars['localhost'].kubeadm_token_expiration }}"
        usage-bootstrap-authentication: "true"
        usage-bootstrap-signing: "true"
  delegate_to: localhost
  run_once: true

- name: Apply bootstrap token
  kubernetes.core.k8s:
    kubeconfig: "{{ k8s_auth_kubeconfig }}"
    state: present
    src: /tmp/bootstrap-token.yaml
    apply: true
  delegate_to: localhost
  run_once: true

- name: Ensure kubeadm bootstrap service account exists
  delegate_to: localhost
  run_once: true
  kubernetes.core.k8s:
    kubeconfig: "{{ k8s_auth_kubeconfig }}"
    state: present
    definition:
      apiVersion: v1
      kind: ServiceAccount
      metadata:
        name: kubeadm-bootstrap
        namespace: kube-system

- name: Bind bootstrap SA to public-info viewer
  delegate_to: localhost
  run_once: true
  kubernetes.core.k8s:
    kubeconfig: "{{ k8s_auth_kubeconfig }}"
    state: present
    definition:
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRoleBinding
      metadata:
        name: kubeadm:sa-bootstrap-public-info
      subjects:
        - kind: ServiceAccount
          name: kubeadm-bootstrap
          namespace: kube-system
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: ClusterRole
        name: system:public-info-viewer

- name: Bind bootstrap SA to kubeadm bootstrap discovery
  delegate_to: localhost
  run_once: true
  kubernetes.core.k8s:
    kubeconfig: "{{ k8s_auth_kubeconfig }}"
    state: present
    definition:
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRoleBinding
      metadata:
        name: kubeadm:sa-bootstrap-discovery
      subjects:
        - kind: ServiceAccount
          name: kubeadm-bootstrap
          namespace: kube-system
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: ClusterRole
        name: kubeadm:bootstrap-discovery

- name: Ensure bootstrap SA can read kubeadm-config ConfigMap
  delegate_to: localhost
  run_once: true
  kubernetes.core.k8s:
    kubeconfig: "{{ k8s_auth_kubeconfig }}"
    state: present
    definition:
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRole
      metadata:
        name: kubeadm:bootstrap-config
      rules:
        - apiGroups: [""]
          resources: ["configmaps"]
          resourceNames: ["kubeadm-config"]
          verbs: ["get", "list", "watch"]

- name: Bind bootstrap SA to kubeadm-config reader
  delegate_to: localhost
  run_once: true
  kubernetes.core.k8s:
    kubeconfig: "{{ k8s_auth_kubeconfig }}"
    state: present
    definition:
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRoleBinding
      metadata:
        name: kubeadm:sa-bootstrap-config
      subjects:
        - kind: ServiceAccount
          name: kubeadm-bootstrap
          namespace: kube-system
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: ClusterRole
        name: kubeadm:bootstrap-config

- name: Ensure bootstrap SA can read kubeadm component ConfigMaps
  delegate_to: localhost
  run_once: true
  kubernetes.core.k8s:
    kubeconfig: "{{ k8s_auth_kubeconfig }}"
    state: present
    definition:
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRole
      metadata:
        name: kubeadm:bootstrap-components
      rules:
        - apiGroups: [""]
          resources: ["configmaps"]
          resourceNames:
            - kubelet-config
            - kube-proxy
          verbs: ["get", "list", "watch"]

- name: Bind bootstrap SA to kubeadm component reader
  delegate_to: localhost
  run_once: true
  kubernetes.core.k8s:
    kubeconfig: "{{ k8s_auth_kubeconfig }}"
    state: present
    definition:
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRoleBinding
      metadata:
        name: kubeadm:sa-bootstrap-components
      subjects:
        - kind: ServiceAccount
          name: kubeadm-bootstrap
          namespace: kube-system
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: ClusterRole
        name: kubeadm:bootstrap-components

- name: Ensure kubeadm-config ConfigMap exists (optional)
  when: kubeadm_manage_config | default(false)
  delegate_to: localhost
  run_once: true
  kubernetes.core.k8s:
    kubeconfig: "{{ k8s_auth_kubeconfig }}"
    state: present
    definition:
      apiVersion: v1
      kind: ConfigMap
      metadata:
        name: kubeadm-config
        namespace: kube-system
      data:
        ClusterConfiguration: |
          apiVersion: kubeadm.k8s.io/v1beta3
          kind: ClusterConfiguration
          kubernetesVersion: "{{ k8s_version | default('1.30.3') }}"
          clusterName: kubernetes
          controlPlaneEndpoint: "{{ (k8s_api_endpoint | regex_replace('^https?://', '')) | default('k8s.dsreed.net:6443') }}"
          networking:
            podSubnet: "{{ k8s_pod_cidr | default('10.244.0.0/16') }}"
            serviceSubnet: "10.0.8.0/21"
        ClusterStatus: |
          apiVersion: kubeadm.k8s.io/v1beta3
          kind: ClusterStatus
          apiEndpoints:
            control-plane:
              advertiseAddress: "{{ (k8s_api_endpoint | regex_replace('^https?://', '')).split(':')[0] | default('k8s.dsreed.net') }}"
              bindPort: {{ ((k8s_api_endpoint | regex_replace('^https?://', '')).split(':') | last | int) | default(6443, true) }}

- name: Bind bootstrap SA to node bootstrapper
  delegate_to: localhost
  run_once: true
  kubernetes.core.k8s:
    kubeconfig: "{{ k8s_auth_kubeconfig }}"
    state: present
    definition:
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRoleBinding
      metadata:
        name: kubeadm:sa-bootstrap-nodeclient
      subjects:
        - kind: ServiceAccount
          name: kubeadm-bootstrap
          namespace: kube-system
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: ClusterRole
        name: system:node-bootstrapper

- name: Auto-approve nodeclient CSRs from bootstrap SA
  delegate_to: localhost
  run_once: true
  kubernetes.core.k8s:
    kubeconfig: "{{ k8s_auth_kubeconfig }}"
    state: present
    definition:
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRoleBinding
      metadata:
        name: kubeadm:sa-bootstrap-approve-nodeclient
      subjects:
        - kind: ServiceAccount
          name: kubeadm-bootstrap
          namespace: kube-system
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: ClusterRole
        name: system:certificates.k8s.io:certificatesigningrequests:nodeclient

- name: Auto-approve cert rotation CSRs from bootstrap SA
  delegate_to: localhost
  run_once: true
  kubernetes.core.k8s:
    kubeconfig: "{{ k8s_auth_kubeconfig }}"
    state: present
    definition:
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRoleBinding
      metadata:
        name: kubeadm:sa-bootstrap-approve-selfnodeclient
      subjects:
        - kind: ServiceAccount
          name: kubeadm-bootstrap
          namespace: kube-system
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: ClusterRole
        name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient

- name: Mint bootstrap service account token
  delegate_to: localhost
  run_once: true
  command: kubectl --kubeconfig {{ k8s_auth_kubeconfig }} -n kube-system create token kubeadm-bootstrap --duration={{ kubeadm_token_ttl_hours | default(24) }}h
  register: sa_token_cmd
  changed_when: true

- name: Set fact for bootstrap service account token
  delegate_to: localhost
  delegate_facts: true
  run_once: true
  set_fact:
    kubeadm_sa_token: "{{ sa_token_cmd.stdout }}"

- name: Fetch cluster CA cert
  command: >
    kubectl --kubeconfig {{ k8s_auth_kubeconfig }}
    config view --raw --flatten -o jsonpath='{.clusters[0].cluster.certificate-authority-data}'
  register: ca_b64
  delegate_to: localhost
  run_once: true
  changed_when: false

- name: Compute discovery token CA cert hash
  shell: |
    echo "{{ ca_b64.stdout }}" | base64 -d > /tmp/ca.crt
    openssl x509 -pubkey -in /tmp/ca.crt | openssl pkey -pubin -outform DER | openssl dgst -sha256 -hex | awk '{print $2}'
  args:
    executable: /bin/bash
  register: ca_hash
  delegate_to: localhost
  run_once: true
  changed_when: false

- name: Ensure kubeadm bootstrap RBAC bindings exist
  delegate_to: localhost
  run_once: true
  kubernetes.core.k8s:
    kubeconfig: "{{ k8s_auth_kubeconfig }}"
    state: present
    definition:
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRoleBinding
      metadata:
        name: kubeadm:bootstrap-signer-clusterinfo
      subjects:
        - kind: Group
          name: system:bootstrappers
          apiGroup: rbac.authorization.k8s.io
        - kind: Group
          name: system:nodes
          apiGroup: rbac.authorization.k8s.io
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: ClusterRole
        name: system:public-info-viewer

- name: Ensure kubeadm auto-approves node client certificates
  delegate_to: localhost
  run_once: true
  kubernetes.core.k8s:
    kubeconfig: "{{ k8s_auth_kubeconfig }}"
    state: present
    definition:
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRoleBinding
      metadata:
        name: kubeadm:node-autoapprove-bootstrap
      subjects:
        - kind: Group
          name: system:bootstrappers
          apiGroup: rbac.authorization.k8s.io
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: ClusterRole
        name: system:certificates.k8s.io:certificatesigningrequests:nodeclient

- name: Ensure kubeadm auto-approves cert rotation
  delegate_to: localhost
  run_once: true
  kubernetes.core.k8s:
    kubeconfig: "{{ k8s_auth_kubeconfig }}"
    state: present
    definition:
      apiVersion: rbac.authorization.k8s.io/v1
      kind: ClusterRoleBinding
      metadata:
        name: kubeadm:node-autoapprove-certificate-rotation
      subjects:
        - kind: Group
          name: system:nodes
          apiGroup: rbac.authorization.k8s.io
      roleRef:
        apiGroup: rbac.authorization.k8s.io
        kind: ClusterRole
        name: system:certificates.k8s.io:certificatesigningrequests:selfnodeclient

# Resolve API endpoint dynamically: prefer explicit var, then env, then terraform output
- name: Derive k8s_api_endpoint from env or terraform (if not set)
  when: (k8s_api_endpoint is not defined) or (k8s_api_endpoint | trim == "")
  block:
    - name: Read K8S_API_ENDPOINT from environment
      set_fact:
        k8s_api_endpoint: "{{ lookup('env', 'K8S_API_ENDPOINT') | default('', true) }}"

    - name: Populate k8s_api_endpoint from terraform output (if still empty)
      when: k8s_api_endpoint | trim == ""
      command: terraform output -raw k8s_api_endpoint
      register: tf_api_ep
      delegate_to: localhost
      changed_when: false
      failed_when: tf_api_ep.rc != 0 or (tf_api_ep.stdout | trim == "")

    - name: Set fact from terraform output
      when: k8s_api_endpoint | trim == ""
      set_fact:
        k8s_api_endpoint: "{{ tf_api_ep.stdout | trim }}"

- name: Default k8s_api_endpoint if still empty
  when: k8s_api_endpoint | default('') | trim == ""
  set_fact:
    k8s_api_endpoint: "k8s.dsreed.net:6443"

- name: Normalize kubeadm API server URL (ensure https scheme)
  set_fact:
    kubeadm_api_server_url: >-
      {% if k8s_api_endpoint is match('^https?://') %}
      {{ k8s_api_endpoint }}
      {% else %}
      https://{{ k8s_api_endpoint }}
      {% endif %}
    kubeadm_api_server_hostport: "{{ (kubeadm_api_server_url | regex_replace('^https?://', '')) | trim }}"

- name: Render discovery kubeconfig for workers
  delegate_to: localhost
  run_once: true
  delegate_facts: true
  set_fact:
    kubeadm_discovery_conf: |
      apiVersion: v1
      kind: Config
      clusters:
      - cluster:
          certificate-authority-data: {{ ca_b64.stdout }}
          server: {{ kubeadm_api_server_url }}
        name: cluster
      contexts:
      - context:
          cluster: cluster
          user: bootstrap
        name: bootstrap
      current-context: bootstrap
      users:
      - name: bootstrap
        user:
          token: {{ hostvars['localhost'].kubeadm_sa_token }}

- name: Push discovery kubeconfig to worker
  copy:
    dest: /etc/kubernetes/kubeadm-discovery.conf
    mode: '0600'
    content: "{{ hostvars['localhost'].kubeadm_discovery_conf }}"

- name: Render kubeadm join config (bootstrap token, LB endpoint, pinned CA hash)
  copy:
    dest: /etc/kubernetes/kubeadm-join.yaml
    mode: '0600'
    content: |
      apiVersion: kubeadm.k8s.io/v1beta3
      kind: JoinConfiguration
      discovery:
        file:
          kubeConfigPath: /etc/kubernetes/kubeadm-discovery.conf
      nodeRegistration:
        criSocket: unix:///var/run/containerd/containerd.sock

- name: Assemble kubeadm join command
  set_fact:
    kubeadm_join_cmd: >-
      kubeadm join --config /etc/kubernetes/kubeadm-join.yaml

- name: Ensure kubeadm present on worker
  ansible.builtin.command: kubeadm version
  register: kubeadm_check
  changed_when: false

- name: Fail if kubeadm missing
  ansible.builtin.fail:
    msg: "kubeadm not found on {{ inventory_hostname }}; install kubeadm/kubelet/kubectl first."
  when: kubeadm_check.rc != 0

- name: Join worker to cluster
  ansible.builtin.command: "{{ kubeadm_join_cmd }}"
  register: join_result
  changed_when: "'This node has joined' in join_result.stdout"

- name: Show join output
  ansible.builtin.debug:
    var: join_result.stdout
